[ { "title": "Testing 101", "url": "/posts/Testing-101/", "categories": "", "tags": "testing", "date": "2022-11-09 03:30:00 +0800", "snippet": "What is software testingSoftware testing is the act of examining the artifacts and the behavior of the software under test by validation and verification. Although software testing can determine the correctness of software under the assumption of some specific hypotheses, testing cannot identify all the failures within the software.The process of testing (software) can be manual or automated. It is obvious that while the automated testing process takes more time for the it’s development, it is easier to run it again and again in the future compared to the manualone. For the context of this page, when we refer to test we will mean an automated software test.Types of testingThere are lots of software testing approaches, each one used for different reasons and has its own benefits ordrawbacks. Hare is a short list presenting how are tests grouped based on different aspects: White Box Testing : verifies the internal structures or workings of a program, as opposed to the functionality exposed to the end-user (also known as clear box testing, glass box testing, transparent box testing, and structural testing). Black Box Testing : treats the software as a “black box,” examining functionality without any knowledge of internal implementation, without seeing the source code (also known as functional testing). Component Interface Testing :a variation of black-box testing, with the focus on the data values beyondthe related actions of a subsystem component. Unit Testing : verify the functionality of a specific section of code, usually at the function level. Integration Testing : seeks to verify the interfaces between components against a software design. System Testing : tests a completely integrated system to verify that the system meets its requirements. Acceptance Testing : conducted to determine if the requirements of a specification or contract are met. It mayinvolve chemical tests, physical tests, or performance tests. Performance Testing : is executed to determine how a system or sub-system performs in terms of responsiveness and stability under a particular workload.We can see that some types of testing do not assist on validating the correctness of a software. They assist us tovalidate some requirements we have set. A great example of such a test group is the Performance testing where we have toreassure that the software produces complies with some performance requirements that we have set.Test pyramidIt makes sense that each different testing types and technique exists to serve a different needor a different approach. Some of them are use to test small code snippets while other are designed to test a system as a whole. The smaller the unit that a test examines for defects it will probably be easier to write andwill probably require less time to run compared to a test that checks a larger portion of a system or codebase.The metaphor of the test pyramid is a way to represent the grouping of tests based on their granularity. Also itprovides a way to give an idea of how many tests we should have in each of these groups.Image CreditsThe main message that the test pyramid gives us is that we have to write more tests that check smaller parts of oursystem or code and less tests that check our system in a more integrated with any 3rd party system or with othersubsystems. Also, the tests that are closer to the top of the pyramid are generally more expensive in terms of development and also slower on their execution. While test pyramid gives us an example of how many tests of each type we should write for our system, we should always adopt this to our own system and its needs.The AAA Arrange Act AssertThis is the triple A (AAA) principle that each test should follow. A test is mainly consisted of these three distinctparts.The Arrange part is the part of each test where we have to prepare all the required and appropriate prerequisites forour test scenario to run. For instance, we have to prepare any data on the database, establish a connection to a3rd party system or even prepare a mock that will be latter used. This part of the test should use as many primitive functionality of our software so that any defect on the higher level functionality wont affect our test.The ACT part is the part of each test where the functionality under test is invoked or triggered in the predeterminedway. The ACT part is usually smaller compared to the other parts at it’s main role is just to trigger the functionalityunder test.The ASSERT part is the part of the test where we have to check that the functionality under test produced the expected results. Such results could be the return value(s) of a function, the data in a Database, a message on a message brokersystem and more. Assertion are the way we endure that the functionality under test had the expected behavior.In many cases within each test we write down a comment indicating each different part of the test://Arrangedb.CreateUser(\"name\", \"email@mail.com\")//Actuser, err := users.GetByName(\"name\")//Assertif err!=nil{ t.Errorf(\"did not expect error, but got one: %v\", err)}if user.Name!=\"name\"{ t.Errorf(\"expected user name %v, but got: %v\", \"name\", user.Name)}if user.Email!=\"email@mail.com\"{ t.Errorf(\"expected user email %v, but got: %v\", \"email@mail.com\", user.Email)}In some case a multiple AAA approach is followed. At multi AAA a test follows multiple Act and Assert phases like:Arrange -&gt; Act -&gt; Assert -&gt; Act -&gt; Assert and so on. While this seems many time a bit tempting to use we should avoidusing it especially in Unit testing where we have to test just a specific functionality.Arrange and Assert parts of the test are pretty crucial. At the arrange part we have to carefully prepare all the prerequisites in order to be able to reproduce the scenario we want to run and test. The assert part is where we verifythat everything went as expected, any data produced are valid and no unwanted data altered or created.CleanupAs we usually run a bunch of tests every time we must reassure that a test does not affect somehow any other test execution - even the exact same test. For this reason it is essential to clean things up as soon as the are no longerrequired. Cleanup should include database records, disk files, 3rd party integrations and even cleanup anything createdby the functionality under test.In go, the defer statement is suitable for such cases://ArrangedbUser := db.CreateUser(\"name\", \"email@mail.com\")//cleanupdefer dbUser.Delete()//Actuser, err := users.GetByName(\"name\")//Assertif err!=nil{ t.Errorf(\"did not expect error, but got one: %v\", err)}if user.Name!=\"name\"{ t.Errorf(\"expected user name %v, but got: %v\", \"name\", user.Name)}if user.Email!=\"email@mail.com\"{ t.Errorf(\"expected user email %v, but got: %v\", \"email@mail.com\", user.Email)}Test coverageTest coverage is a percentage measure of the degree to which the source code of a program is executed when a particulartest suite is run. Each line of the source code executed during a test execution is considered as test covered. The more the lines we cover with our test the higher the test coverage of our tests.Text coverage is measured in percentage and usually a bare minimum it pursued to be achieved.Ensuring a minimum value to this measurement during the lifecycle of the development process,indicates that we value the necessity of the tests.Trusting the testsTest coverage is a great tool when it come for gaining trust to a test. When we execute a test with test coveragedetails we ψαν review each line covered by that test. Using this approach we can identify if the lines covered by the test are the expected ones. It’s a common case that a test could expect some error but not checking the specific errormight cause a successful test but not checking the expected behavior.Higher test coverage does not necessarily mean that a program has fewer bugs. While test coverage is measured by the degree to which the source code of a program is executed when a particular test suite is run this does not impliesthat we are have the right assertions for each part of our code. This means that we can simply achieve a hight testcoverage (even 100%) and we could change our source code without having any test to fail! More details on this can befound on a previous post about Testing the Tests where a techniquecalled Mutation testing is presented which verifies the existing tests with an automated way.Wrap upAs we saw earlier, there are lots of different testing approaches and techniques. Each one has its own benefits anddrawbacks. As each project has its own features and particular requirements we must carefully select which types of tests and up to what a degree are required. Testing is a difficult path, sometime more difficult than the software development. While doing it right can be very beneficial, doing it in a not do appropriate way might make our work harder." }, { "title": "Embedding VCS Info in Go binary", "url": "/posts/Embedding-VCS-Info-in-Binary/", "categories": "", "tags": "golang, coding", "date": "2022-01-16 18:15:00 +0800", "snippet": "Binaries we produce from our applications are something like black boxes! When we create and distribute Go binaries we cannon distinguish somehow the version of the binary or any other metadata. Unless we deliberately add appropriate codeand update it on every single build we make we cannot offer this capability. It makes sense that when we want to be able to identify different versions of our application from each binary directly.Embedding various metadata within our binary can significantly improve debugging , monitoring, logging and more.Version Control System (VCS) information, build time and build environment are some metadata that when included within the binary will make our lives easier!Go offers two ways for adding such metadata within a binary. The first one presented is using special flags that are used at compile time to pass within the binary the appropriate metadata. The second way is available from Go version 1.18 onwards and makes use of the Debug package.Using Build Link FlagsGo’s rich tooling provides a mechanism that reads the Go archive or object for a package main, along with its dependencies, and combines them into an executable binary. This is available through the cmd/link packageAn option named -ldflags is available through the build command which allows the insertion of dynamic information to the binary at build time without any modification or our source code.In order to understand how -ldflags option works we can examine the following code snippet:package mainimport \"fmt\"var Version = \"0.9\"var BuildTime = \"2022-01-01 00:00\"func main(){\tfmt.Println(\"Hello build info!\")\tfmt.Println(\"Version:\\t\" +Version)\tfmt.Println(\"Built @:\\t\" +BuildTime)}We can clearly see that our app will compile and when run it will produce the following output:$ go build -o main .$ ./main Hello build info! Version:\tv0.9 Built @:\t2022-01-01 00:00As mentioned earlier, we are able to use -ldflags at build time in order to pass in flags to the go tool link which runs as a part of the go build process. It’s syntax is$ go build -ldflags=\"-flag\" -o main .Using this syntax we can pass multiple different link flags to our binary at build time. In our example we are going to use the -X flag which allows us to write information to a variable. The syntax of the ldflags using th -X option is:$ go build -ldflags=\"-X 'package_name.variable_name=value'\" -o main .Where variable_name is the name of the variable we want to replace and package_name the name of the package that the variable resides. value is the new value of the variable we want to assign. So, back to our application, we would like to add the current version and the real build time. This can be achieved by using the following build command:$ go build -ldflags=\"-X 'main.Version=v1.0.0' -X 'main.BuildTime=$(date)'\" -o main .Running our app after the successful build we we get this output:$ ./main Hello build info! Version:\tv1.0.0 Built @:\tFri Jan 14 18:41:49 EET 2022We can see that our new desired values of the specific variables have been linked to our binary successfully.This way we can replace any specific value within any package of our application at build time which can provide vitalassistance when investigating issues. It is more convenient to automate the build process while using -ldfags so that the binary includes all the required information. A make file might be a possible solution!A worth mentioning tool here is the go tool nm. This tool lists the symbols defined or used by an object file, archive, or executable. For our executable we can invoke it like this:$ go tool nm ./main | grep main 1124020 D main..inittask 1133f70 D main.BuildTime 10bf660 R main.BuildTime.str 1133f80 D main.Version 10beeb4 R main.Version.str 108a0c0 T main.main 1031b00 T runtime.main...Here we can see that the variables we used are within this list. This way we can easily find any available variable and build again the application replacing them.So in a last example where we want to provide our binary with the last commit’s hash we can use the following source:package mainimport \"fmt\"var Version = \"0.9\"var BuildTime = \"2022-01-01 00:00\"var CommitHash = \"\"func main(){\tfmt.Println(\"Hello build info!\")\tfmt.Println(\"Version:\\t\" +Version)\tfmt.Println(\"Built @:\\t\" +BuildTime)\tfmt.Println(\"Commit:\\t\" +CommitHash)}and then build and run our application:$ go build -ldflags=\"-X 'main.Version=v1.0.0' -X 'main.BuildTime=$(date)' -X 'main.CommitHash=$(git rev-parse HEAD)'\" -o main .$ ./main Hello build info! Version:\tv1.0.0 Built @:\tSat Jan 14 18:31:14 EET 2022 Commit:\t52519871fd3199ec66becab0dc8b14fbdbdbfdceUsing the Debug packageFrom Go 1.18 onwards Go provides a structure that has been updated to include a new field Settings []debug.BuildSettingThe runtime/debug.BuildInfo returned by runtime/debug.ReadBuildInfo() returns a key-value pairs describing a binary. In order to see this new feature in action we can use the following source:package mainimport (\t\"fmt\"\t\"runtime/debug\")func main() {\tfmt.Println(\"Hello build info!\")\tinfo, ok := debug.ReadBuildInfo()\tif !ok {\t\treturn\t}\tfmt.Println(\"Key:\\tValue\")\tfor _, kv := range info.Settings {\t\tfmt.Println(kv.Key + \":\\t\" + kv.Value)\t}}We can now build our application as usual and then run it:$ go build -o main . $ ./main Hello build info! Key:\tValue -compiler:\tgc CGO_ENABLED:\t1 CGO_CFLAGS:\t CGO_CPPFLAGS:\t CGO_CXXFLAGS:\t CGO_LDFLAGS:\t GOARCH:\tamd64 GOOS:\tdarwin GOAMD64:\tv1 vcs:\tgit vcs.revision:\t4071203188d039a852220d88dad45df0dbfaae7a vcs.time:\t2022-01-15T16:47:19Z vcs.modified:\ttrueFrom those available build info we can review some Go specific attributes that used at build time such as the GOARCH andthe GOOS, and also within the vcs object we can see some specific attributes about the Version Control System (VCS)that this app might use. In our case we have used the git VCS and there are some specific attributes set. The vcs.revision is the last’s commit’s hash, the vcs.time is the time that the commit was made and the vcs.modifiedattribute signifies if the source has been modified or not since the last commit.Sum UpWe have seen how we can use ldflags to inject valuable information into Go binaries at build time. Using this feature we can pass through feature flags, environment information, versioning information, and more without altering our source code. Apart from this, from Go 1.18, we can exploit the BuildSetting available through theruntime/debug.BuildInfo in order to retrieve valuable information about our VCS state at build time. Of course, wecan combine both solutions to achieve the desired outcome from our binaries!" }, { "title": "Testing the Tests", "url": "/posts/Testing-the-Tests/", "categories": "", "tags": "golang, coding, testing", "date": "2021-09-11 02:15:00 +0800", "snippet": "If we use tests to test code, how can we test our tests? We write tests in order to assure the quality of the software we are writing. Software developers are usually trying to reach a certain level of code coverage through their tests. However, the quality of the tests is not usually measured or examined through this process. It is possible that someone could achieve a 100% code coverage even without any assertion at all!Is it Fully Tested?In a simple example we have a fizzbuzz implementation where given an integer we return the desired string result:package fizzbuzzimport \"strconv\"// CalculateFizzBuzz returns// `fizz` if the given number is divisible by 3// `buzz` if the given number is divisible by 5// `fizzbuzz` if the given number is divisible by 3 and 5// empty string if it is non positive// else the number itself.func CalculateFizzBuzz(num int) string {\tret := \"\"\tif num &lt;= 0 {\t\treturn ret\t}\tif num%3 == 0 {\t\tret += \"fizz\"\t}\tif num%5 == 0 {\t\tret += \"buzz\"\t}\tif num%3 != 0 &amp;&amp; num%5 != 0 {\t\tret = strconv.Itoa(num)\t}\treturn ret}Testing this function seems straight forward. We have to test all the if statements of the function. Using table testing technique we can have the following result for our test cases:package fizzbuzzimport \"testing\"func TestCalculateFizzBuzz(t *testing.T) {\tvar tt = []struct {\t\tname string\t\tgiven int\t\texpected string\t}{\t\t{\t\t\tname: \"Given -1 expects empty string.\",\t\t\tgiven: -1,\t\t\texpected: \"\",\t\t},\t\t{\t\t\tname: \"Given 3 expects fizz.\",\t\t\tgiven: 3,\t\t\texpected: \"fizz\",\t\t},\t\t{\t\t\tname: \"Given 5 expects buzz.\",\t\t\tgiven: 5,\t\t\texpected: \"buzz\",\t\t},\t\t{\t\t\tname: \"Given 15 expects fizzbuzz.\",\t\t\tgiven: 15,\t\t\texpected: \"fizzbuzz\",\t\t},\t\t{\t\t\tname: \"Given 7 expects 7.\",\t\t\tgiven: 7,\t\t\texpected: \"7\",\t\t},\t}\tfor _, tc := range tt {\t\tt.Run(tc.name, func(t *testing.T) {\t\t\t//Test\t\t\tgot := CalculateFizzBuzz(tc.given)\t\t\t//Assert\t\t\tif got != tc.expected {\t\t\t\tt.Fatalf(\"expected: %s, got: %s, for CalculateFizzBuzz of %d\", tc.expected, got, tc.given)\t\t\t}\t\t})\t}}Test coverage can be seen by executing these commands:go test -coverprofile cover.out go tool cover -html=cover.outand the result is:As we see our code is 100% covered by tests. Does this mean that we are safe to do any change to our code with thesafety net of our tests? Absolutely not!Let’s see a simple example. Changing the line if num &lt;= 0 { to if num &lt; 0 { will still let all the tests to passsuccessfully, however, we just changed our function’s behavior with unexpected results in the execution.Lets see another example. Removing these test cases:{\tname: \"Given 5 expects buzz.\",\tgiven: 5,\texpected: \"buzz\",},{\tname: \"Given 15 expects fizzbuzz.\",\tgiven: 15,\texpected: \"fizzbuzz\",},will also leave our coverage untouched and up to 100%. However, we have missed out to test specific cases of our function.There is one certain technique that allows us to detect such cases. This technique involves the process to apply minor changes to our function and then check if the existing tests fail on each one of those! This process can be automated through mutation testing!Mutation to the rescue!Mutation testing is used to design new software tests and evaluate the quality of existing software tests. Mutation testing involves modifying a program in small ways. Each mutated version is called a mutant and tests detect and reject mutants by causing the behavior of the original version to differ from the mutant. This is called killing the mutant. Test suites are measured by the percentage of mutants that they kill. New tests can be designed to kill additional mutants. Mutants are based on well-defined mutation operators that either mimic typical programming errors (such as using the wrong operator or variable name) or force the creation of valuable tests (such as dividing each expression by zero). The purpose is to help the tester develop effective tests or locate weaknesses in the test data used for the program or in sections of the code that are seldom or never accessed during execution. Mutation testing is a form of white-box testing. (https://en.wikipedia.org/wiki/Mutation_testing)The mutation testing can be automated through a mutation library. Such libraries mutate the source code in minor ways through a specific rule-set and then they run the same tests against the produced mutant. In our case we used the go-mutesting library to run such a process.&gt;&gt; go-mutesting/fizbuzz.goPASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-718515268/fizzbuzz/fizbuzz.go.0\" with checksum 8f404742ff5b871908bdf580620787c2PASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-718515268/fizzbuzz/fizbuzz.go.1\" with checksum df615b5ba4c9d06bb54cf605730d89b8PASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-718515268/fizzbuzz/fizbuzz.go.2\" with checksum 15e3b2a8de455eed5e05c73dbbf1263fPASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-718515268/fizzbuzz/fizbuzz.go.3\" with checksum 933cd06e194200a78f53199c1d3ddfb6--- fizzbuzz/fizbuzz.go\t2021-09-07 11:48:32.000000000 +0300+++ /var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-718515268/fizzbuzz/fizbuzz.go.4\t2021-09-07 22:37:29.000000000 +0300@@ -10,7 +10,7 @@ // else the number itself. func CalculateFizzBuzz(num int) string { \tret := \"\"-\tif num &lt;= 0 {+\tif num &lt; 0 { \t\treturn ret \t} \tif num%3 == 0 {FAIL \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-718515268/fizzbuzz/fizbuzz.go.4\" with checksum 9970f3c67a1e9211513823f2d4549314PASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-718515268/fizzbuzz/fizbuzz.go.5\" with checksum a26848fafc97ee7d8ef7d7a497a12f82PASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-718515268/fizzbuzz/fizbuzz.go.6\" with checksum 802ed71e97906862491cfaf7a506754dThe mutation score is 0.857143 (6 passed, 1 failed, 3 duplicated, 0 skipped, total is 7)We can see that go-mutesting produced 7 mutants of our source code and just one of those failed.In the failed one the altered line is mentioned as-\tif num &lt;= 0 {+\tif num &lt; 0 {We can fix this by altering our first test case to:{\tname: \"Given 0 expects empty string.\",\tgiven: 0,\texpected: \"\",},Here is a demo of how our source code updated while running the mutation testing:Also if we remove these test cases from our test (which also leaves code’s test coverage up to 100%):{\tname: \"Given 5 expects buzz.\",\tgiven: 5,\texpected: \"buzz\",},{\tname: \"Given 15 expects fizzbuzz.\",\tgiven: 15,\texpected: \"fizzbuzz\",},and then run again the mutation testing we get this result: &gt;&gt; go-mutesting fizzbuzz/fizbuzz.goPASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.0\" with checksum 8f404742ff5b871908bdf580620787c2PASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.1\" with checksum df615b5ba4c9d06bb54cf605730d89b8PASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.2\" with checksum 15e3b2a8de455eed5e05c73dbbf1263fPASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.3\" with checksum 933cd06e194200a78f53199c1d3ddfb6PASS \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.4\" with checksum 9970f3c67a1e9211513823f2d4549314--- fizzbuzz/fizbuzz.go\t2021-09-07 11:48:32.000000000 +0300+++ /var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.5\t2021-09-07 22:53:28.000000000 +0300@@ -19,7 +19,7 @@ \tif num%5 == 0 { \t\tret += \"buzz\" \t}-\tif num%3 != 0 &amp;&amp; num%5 != 0 {+\tif true &amp;&amp; num%5 != 0 { \t\tret = strconv.Itoa(num) \t} \treturn retFAIL \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.5\" with checksum a26848fafc97ee7d8ef7d7a497a12f82--- fizzbuzz/fizbuzz.go\t2021-09-07 11:48:32.000000000 +0300+++ /var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.6\t2021-09-07 22:53:28.000000000 +0300@@ -19,7 +19,7 @@ \tif num%5 == 0 { \t\tret += \"buzz\" \t}-\tif num%3 != 0 &amp;&amp; num%5 != 0 {+\tif num%3 != 0 &amp;&amp; true { \t\tret = strconv.Itoa(num) \t} \treturn retFAIL \"/var/folders/jh/nh1wg3r93xv94jd2bwz8lzc80000gn/T/go-mutesting-254713350/fizzbuzz/fizbuzz.go.6\" with checksum 802ed71e97906862491cfaf7a506754dThe mutation score is 0.714286 (5 passed, 2 failed, 3 duplicated, 0 skipped, total is 7)As we still have 100% test coverage, mutation testing revealed cases where our tests fail to catch such alterations to the source code. The mutation score is calculated as the percentage ration of (number of killed mutants)/(number of total mutants).Mutation variationsEach mutation testing library can produce mutants by applying specific changes on the source code based on various rules. The most popular ones are: Branch mutators Expression mutators Statement mutatorsIt makes sense that mutation testing is pretty resource-intensive as there is a huge number of mutants that are usually generated for every code block.Some mutations can cause a test not to finish, so generally, mutation libraries allow each test to run within a ten times compared to the original execution time.Also many tests might generate false positives, so most of the libraries allows us to blacklist specific mutants in order to avoid noise in future runs.Sum UpEven though we try to assure the quality of the software we are writing through the test, nothing validates the efficiency of the tests. Even code coverage of tests might be a misleading qualifier sometimes.Mutation testing involves modifying a program in small ways so that to verify if tests cover each one of this variation (mutant). This way we can qualify if our tests are able to kill all of the mutants effectively.The process of mutating a source code and running the test suite is a pretty resource-intensive process so we should consider how often we can run the mutation testing towards our codebase." }, { "title": "Exec.Command", "url": "/posts/Exec-Command/", "categories": "", "tags": "golang, coding, shell", "date": "2021-05-07 00:40:00 +0800", "snippet": "One of the key features of Go is the considerably rich standard library. Go’s os package offers a wide range of methods and functions to allow programmers to exploit the host’s OS capabilities. Using it leaves us with almost no need to invoke system commands. However, we need sometimes to execute a custom bash script or a system command not supported by some library or just invoke a 3rd party’s executable file!Go provides a pretty handy mechanism to manage - not just execute - system commands. The os/exec package is the mechanism that Go provides to run external commands and we are going to examine it here! Unlike the “system” library call from C and other languages, the os/exec package intentionally does not invoke the system shell and does not expand any glob patterns or handle other expansions, pipelines, or redirections typically done by shells.Executing a command in GoExecuting a system command In Go can be initialized by invoking the os/exec’s command Command().The most common way to execute the command is to use the Run() method:package mainimport (\t\"log\"\t\"os/exec\")func main() {\tcmd := exec.Command(\"date\")\terr := cmd.Run()\tif err != nil {\t\tlog.Fatalf(\"cmd.Run() failed with %s\\n\", err)\t}}In this example we are running the date command. The command is initialized through the cmd := exec.Command(\"date\") command which returns an exec.Cmd struct to execute the named program with the given arguments. cmd.Run() executes the given command and the returned error is nil if the command runs, has no problems copying stdin, stdout, and stderr, and exits with a zero exit status.The cmd structThe exec.Cmd struct is the return value of an exec.Command() function. Cmd represents an external command being prepared or run.A Cmd cannot be reused after calling its Run, Output, or CombinedOutput methods which are presented at the following chapters. This struct contains all the information required for a command to be described before execution and its public fields are more or less self explanatory:type Cmd struct {\tPath string\tArgs []string\tEnv []string\tDir string\tStdin io.Reader\tStdout io.Writer\tStderr io.Writer\tExtraFiles []*os.File\tSysProcAttr *syscall.SysProcAttr\tProcess *os.Process\tProcessState *os.ProcessState}In our previous example, using the cmd := exec.Command(\"date\") we just initialized the Cmd struct with the Path of the date command and no data provided for the Args.More details about the Cmd struct can be found at the golang.org. Note - I’m writing this post on a MacOS using commands that may not work on other OS such as Linux or Windows.Capturing the command’s outputIn our example, after executing the date command we do not retrieve the returned data. It is really common task to retrieve the returned data after executing a command in order to process them appropriately.package mainimport (\t\"fmt\"\t\"log\"\t\"os/exec\")func main() {\tcmd := exec.Command(\"date\")\tdt, err := cmd.Output()\tif err != nil {\t\tlog.Fatalf(\"cmd.Run() failed with %s\\n\", err)\t}\tfmt.Println(string(dt))}The example above will print the current system’s date upon running:Mon 4 May 2021 22:46:33 EESTThe output returned by a cmd.Output() execution is a byte array that can the managed as a string for further processing.Providing arguments to the commandThere are cases where we have to provide extra arguments to our command for execution. This is feasible using the same exec.Command() function where arguments can be provided after the command’s name: func Command(name string, arg ...string) *Cmd. Each argument should be supplied as a different arg. For instance if we have to set up a command for the ls -al /tmp/ command we have to invoke exec.Command(\"ls\", \"-al\", \"/tmp/\"). exec.Command() is an example of a Variadic Function. Variadic Functions can be called with any number of trailing arguments, therefore, we can pass in as many arguments to our initial command as we desire.Splitting command’s argsPreparing to execute a command using Go’s exec.Command() function can sometimes be painful - especially when we have to provide lots of arguments to our command. Thankfully we can prepare our command as one string and then use the strings.fields() function to split it to separate arguments.package mainimport (\t\"fmt\"\t\"log\"\t\"os/exec\"\t\"strings\")func main() {\tcmdStr := \"ls -al /tmp/\"\tcmdArgs := strings.Fields(cmdStr)\tcmd := exec.Command(cmdArgs[0], cmdArgs[1:]...)\tdt, err := cmd.Output()\tif err != nil {\t\tlog.Fatalf(\"cmd.Run() failed with %s\\n\", err)\t}\tfmt.Println(string(dt))}In the example above we prepared our command ls -al /tmp/ as a string, then split its fields, and used the first element as the command to execute while the rest of the fields used as arguments. As Fields splits the string around each instance of one or more consecutive white space characters, we have to take extra care when using it - especially when we have space characters within a single arguments.Other ways of executing a commandThere are cases where we want to initiate a command’s execution without having to wait until its completion. Especially when we have to execute long-running shell scripts where we don’t expect some output we can initiate a command using the Start() method.In some cases we just have to wait or completion of a command we can use the Wait() method. In addition to the Run() method, Wait() waits for the command to exit and waits for any copying to stdin or copying from stdout or stderr to complete.We saw previously how we can capture a command’s output using the Output() method. In cases we want to capture the standard error as well, then we can use the CombinedOutput() method. This method behaves exactly like the Output method and has the same signature.Using commands’ pipesIn an exec.Command() we can provide the Stdin which specifies the process’s standard input. The StdinPipe returns a pipe that will be connected to the command’s standard input when the command starts. In the example below we can see how can we exploit this provided Cmd.StdinPipe in order to feed our cat command with some text upon startup:package mainimport ( \"fmt\" \"io\" \"log\" \"os/exec\")func main() { cmd := exec.Command(\"cat\") stdin, err := cmd.StdinPipe() if err != nil { log.Fatal(err) } go func() { defer stdin.Close() io.WriteString(stdin, \"some random text\") }() out, err := cmd.CombinedOutput() if err != nil { log.Fatal(err) } fmt.Printf(\"%s\\n\", out)}In this example we expect the output to be: some random text.Accordingly, we can exploit a command’s Cmd.StdoutPipe in order to grab the output of the executed command as a stream.A hint 😉As we saw there are various ways we are able to prepare a command for execution using Go’s exec.Command. Most of the times we are adding parameters and conditional arguments while “preparing” a command for execution. Most of the times we have to log a command before execution. exec.Command() provides the String() method which allows us to print the final form of the command for execution.package mainimport (\t\"fmt\"\t\"os/exec\"\t\"strings\")func main() {\tcommand := \"ls\"\tpath := \"/tmp/\"\tcmdStr := command + \" -al \" + path\tcmdArgs := strings.Fields(cmdStr)\tcmd := exec.Command(cmdArgs[0], cmdArgs[1:]...)\tfmt.Println(cmd.String())}The result of the program above should be: ls -al /tmp/. So, using the String() method of a command we can easily retrieve the command we are going to execute!Sum UpUsing Go to manage and execute commands within our apps is a common use case. Go provides, through the exec package, a variety of functions and methods to support such tasks. By exploiting the Command struct we have a pretty powerful way to manage and execute commands according to our needs." }, { "title": "Deep Dive in Go Channels", "url": "/posts/Deep-Dive-in-Go-Channels/", "categories": "", "tags": "golang, coding", "date": "2020-10-31 13:55:00 +0800", "snippet": "One of the biggest advantages of Go is undoubtedly it’s concurrency management. Goroutines are the main feature that Go uses to achieve this. Goroutines wouldn’t be so easy if there wasn’t for channels. A goroutine is a lightweight thread managed by the Go runtime.Channels are the pipes that connect concurrent goroutines. You can send values into channels from one goroutine and receive those values into another goroutine.How channels workGo provides a simple and straightforward mechanism to manage channels that allows goroutines to send and receive values from other gorourtines.A new channel can be created by invoking the make command like this make(chan value-type). value-type is the type of values that the generated channel will hold and transfer.Sending a value through a channel can be done by a-channel &lt;- a-value.Receiving a value from a channel can be done by a-value := &lt;- a-channel.The following example illustrates a simple scenario where a goroutine send a value to a channel whilepackage mainimport (\t\"fmt\"\t\"time\")func main() {\tmessages := make(chan string)\tgo func() {\t\ttime.Sleep(time.Second * 5)\t\tmessages &lt;- \"ping\"\t}()\tmsg := &lt;-messages\tfmt.Println(msg)}In our example, the main functions create a channel of type string and the spawned goroutine waits for 5” before sending a “ping” message through this channel. Main function blocks at receiving data from the channel at line 14 until the data is received and then prints the received data (“ping”) and exits.Buffered and unbuffered channelsThe example we saw exploited the functionality of an unbuffered channel. The size of the channel was 0 which shows the capacity of a channel. For an unbuffered channel, we can only send data if there is a corresponding receive statement - otherwise, it blocks.To illustrate this example we can see that running the following example, pong message can be sent after 5” when the 2nd receive is initiated.package mainimport (\t\"fmt\"\t\"time\")func main() {\tmessages := make(chan string)\tgo func() {\t\tmessages &lt;- \"ping\"\t\tfmt.Println(\"ping sent\")\t\tmessages &lt;- \"pong\"\t\tfmt.Println(\"pong sent\")\t}()\tfmt.Println(&lt;-messages)\ttime.Sleep(time.Second * 5)\tfmt.Println(&lt;-messages)}The output we get from this example is:&gt;/ go run main.goping sentping# here we have a 5\" pausepongpong sentWe can see that send is blocked until the recipient is present.Let’s see now buffered channels in go. A buffered channel in go accepts a limited number of values without a corresponding receiver for those values. A buffered channel is created also by calling make but now an extra argument has to be provided that indicates the buffer size of the channel make(chan value-type, buffer-size).Changing in the previous example the channel construction line to messages := make(chan string, 2) will produce the following output:/&gt; go run main.goping sentpong sentping# here we have a 5\" pausepongBidirectional channelsWe have seen that the same channel is used to send and receive data. However, when passing a channel to a function we can specify if the function is going to send or receive message(s) from the channel. This feature increases the type-safety of the program.The way of defining this feature is at the functions header. A sender only function will be:func sender(messages chan&lt;- string)a receiver only function will be:func receiver(messages &lt;-chan string)Closing a channelClosing a channel signifies that no more data will be sent through this. This is a really useful feature that is used to inform receivers that channel’s sending has been completed.Closing a channel can be done through close(messages) and while receiving we have to check if the channel has closed. To do so we can add one more return value to the receiver of our channel:message, more := &lt;-messagesif more { fmt.Println(\"received message\", j)} else { fmt.Println(\"received all messages\")}A real-world scenarioIn a more real-word scenario now let’s examine three two goroutines should handle sending and receiving data as a sequential process.Let’s assume we need 3 services that serially process data. The first one generates numbers (Counter) the second one doubles them (Doubler) and the last one prints the result (Printer). This is presented in the following schema:+---------------+ +---------------+ +---------------+| | 1,2,3 | | 2,4,6 | || Counter |+----------&gt;| Doubler |+----------&gt;| Printer || | numbers | | doubles | |+---------------+ +---------------+ +---------------+All data exchange between goroutines should be explicitly done through different channels. Each goroutine should only send or receive to/from each channel.package mainimport (\t\"fmt\"\t\"os\"\t\"os/signal\"\t\"sync\"\t\"syscall\")func main() {\tnumbers := make(chan int)\tdoubles := make(chan int)\tvar wg sync.WaitGroup\tsigs := make(chan os.Signal, 1)\tsignal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM)\tdone := make(chan bool, 1)\tgo func() {\t\tsig := &lt;-sigs\t\tfmt.Println()\t\tfmt.Println(sig)\t\tdone &lt;- true\t}()\t\twg.Add(3)\tgo counter(&amp;wg, numbers, done)\tgo doubler(&amp;wg, numbers, doubles)\tgo printer(&amp;wg, doubles)\twg.Wait()}func counter(wg *sync.WaitGroup, numbers chan&lt;- int, done &lt;-chan bool) {\tdefer wg.Done()\ttotalSent := 0\tfor x := 0; ; x++ {\t\tnumbers &lt;- x\t\ttotalSent++\t\tselect {\t\tcase _, ok := &lt;-done:\t\t\tif ok {\t\t\t\tclose(numbers)\t\t\t\tfmt.Printf(\"Closing numbers. Total Sent: %d\\n\", totalSent)\t\t\t\treturn\t\t\t}\t\tdefault:\t\t}\t}}func doubler(wg *sync.WaitGroup, numbers &lt;-chan int, doubles chan&lt;- int) {\tdefer wg.Done()\tfor {\t\tx, more := &lt;-numbers\t\tif !more {\t\t\tclose(doubles)\t\t\tfmt.Println(\"Closing doubles\")\t\t\treturn\t\t}\t\tdoubles &lt;- (2 * x)\t}}func printer(wg *sync.WaitGroup, doubles &lt;-chan int) {\tdefer wg.Done()\ttotalReceived := 0\tfor {\t\td, more := &lt;-doubles\t\tif !more {\t\t\tfmt.Printf(\"Closing Printer. Total Received %d\\n\", totalReceived)\t\t\treturn\t\t}\t\ttotalReceived++\t\tfmt.Println(d)\t}}We can see that all goroutines either consume or produce data to each given channel. counter() just sends to numbers channel, doubler() receives from numbers and sends to doubles and printer() just receives from doubler channel.A sync.WaitGroup is used to allow our main function to wait for all three goroutines to end before exiting. This allows all threads to gracefully finish their jobsLines 14 to 23 are used to exit our application and gorourines. When a SIGINT or SIGTERM signals are received a special (for our application!) channel named done is used to signal the counter() function that it should stop producing new numbers. Closing the numbers allows us in the doubler() function to close the doubles channel as soon as all numbers have been processed. Then printer() can print all doubles and return.Sum UpWe have seen some basic concepts of channels in go. Channels allow our goroutines to exchange data in a thread-safe way. Lots of options are provided to meet an application’s need. We’ve seen how to create channels. the difference between buffered and unbuffered channels, how to close a channel, and how to perceive that a channel has closed!Channels are widely used in go apps especially when exploiting go’s concurrency mechanisms. Hope that this post will give you a better understanding of channels in go." }, { "title": "Testing When Time Matters", "url": "/posts/Testing-When-Time-Matters/", "categories": "", "tags": "golang, testing, time", "date": "2020-09-27 01:55:00 +0800", "snippet": "Software testing undeniably can provide objective, independent information about the quality of software. However, the testing development process can sometimes be not straightforward. There are cases - not so rare - that the development of a test requires a significant amount of effort and time. One of these cases is when we have to test code that is dependant on the current time.The issueDeveloping processes that depend on the current time or elapsed time is not a rare case. There are many cases we need to use the current time and diverse a program’s execution depending on time, duration, or a period. A few examples are schedulers, expirations, repetitive tasks, timeouts, and more…A sample case of a library in Go that is dependant on time is a key-value store that uses expiration on each pair. Such a Store should have the following structuretype DataStore struct {\tData map[string]mapValue\tDeletePrecision time.Duration}type MapValue struct {\tExpiration time.Time\tValue interface{}}Each store has a deletePrecision duration which signifies the amount of time that it checks for expired data. Also mapValue.expiration is a time.Time which signifies the expiration of each mapValue.value that is added in the DataStore.A function that checks and deletes expired mapValues could Periodically run every deletePrecision duration as seen bellow:func (ds *DataStore) DeleteExpiredKeys() {\tcheckIntervalTicker := time.NewTicker(ds.DeletePrecision)\tfor {\t\t&lt;- checkIntervalTicker.C // every ds.deletePrecision duration\t\tds.checkAndDeleteExpiredKeys()\t}}func (ds *DataStore) checkAndDeleteExpiredKeys() {\tfor key, data := range ds.Data {\t\tnow := time.Now()\t\tif data.Expiration.Before(now) {\t\t\tdelete(ds.Data, key)\t\t}\t}}So, when we need to test checkAndDeleteExpiredKeys() function we face an issue. Our function depends on an uncontrollable resource:Current TimeThis means that when we have to write a test for the checkAndDeleteExpiredKeys() function we should appropriately set up a mapValue object with an expiration, check the time elapsed and then run the checkAndDeleteExpiredKeys() function before any assertion. This leaves us to have a test with some sleeping time in order to avoid any false negatives in our test:func TestCheckAndDeleteExpiredKeys(t *testing.T) { ds := DataStore{\t\tData: map[string]mapValue{},\t\tDeletePrecision: precision, } ds.Data[\"akey\"] = mapValue{ expiration: ds.Clock.Now().Add(500*time.Millisecond),\t\tvalue: \"avalue\", } time.Sleep(300 * time.Millisecond) ds.checkAndDeleteExpiredKeys() if _, exists := ds.Data[\"akey\"] ; !exists { t.Errorf(\"Key-value not found but should\") } time.Sleep(300 * time.Millisecond) ds.checkAndDeleteExpiredKeys() if _, exists := ds.Data[\"akey\"] ; exists { t.Errorf(\"Key-value found but shouldn't\") }}Looking into this test it is clear that, adding a delay in our test to verify the correctness of a function, is not a desirable process at all. Apart from the fact that our unit test now adds an extra delay to the testing process, it is clear that trying to minimize this delay might affect our test. Also, this way of testing makes our test less easy to maintain and more prone to errors.Some theoryAs seen above our function is tightly coupled with a resource we don’t have control on. Current time. Decoupling our function from this external resource is essential for unit testing.The most common way to achieve this decoupling is by using Dependency Injection (DI).According to Wikipedia: In software engineering, dependency injection is a technique in which an object receives other objects that it depends on. These other objects are called dependencies. In the typical “using” relationship the receiving object is called a client and the passed (that is, “injected”) object is called a service. The code that passes the service to the client can be many kinds of things and is called the injector. Instead of the client specifying which service it will use, the injector tells the client what service to use. The “injection” refers to the passing of a dependency (a service) into the object (a client) that would use it.Dependency injection is one form of the broader technique of inversion of control. A client who wants to call some services should not have to know how to construct those services. Instead, the client delegates the responsibility of providing its services to external code (the injector).But the intent of this technique is this: The intent behind dependency injection is to achieve separation of concerns of construction and use of objects. This can increase readability and code reusability.The solutionComing back to our case, we should now follow the separation of concerns through DI in our scenario, in order to give us the ability to test our function. This means we should provide each DataStore object with an interface that implements a Now() function. This should return the current time in all cases but when we are testing our checkAndDeleteExpiredKeys() function we could override it.So, Datastore should now have the following form:type DataStore struct { Data map[string]mapValue DeletePrecision time.Duration Clock Clock}// Clock is an interface that provides a single function// to return the current time which is used for checking expiration.type Clock interface {\tNow() time.Time}The default SystemClock provided below could be used by default in each New Datastore:// SystemClock implements Clock interface that uses time.Now().var SystemClock = systemClock{}type systemClock struct{}func (t systemClock) Now() time.Time {\treturn time.Now()}However, during our unit test, we can inject an implementation of the Clock interface that we could control the Now() function’s results so that we can alter the “current” time based on the test!So our test can now be formed like this:type pastClock struct{}var PastClock = pastClock{}func (t pastClock) Now() time.Time {\tpt, _ := time.Parse(time.RFC3339, \"2000-01-01T00:00:00+00:00\")\treturn pt}type futureClock struct{}var FutureClock = futureClock{}func (t futureClock) Now() time.Time {\tpt, _ := time.Parse(time.RFC3339, \"3000-01-01T00:00:00+00:00\")\treturn pt}func TestCheckAndDeleteExpiredKeys(t *testing.T) { ds := DataStore{\t\tData: map[string]mapValue{}, DeletePrecision: precision, Clock: PastClock } ds.Data[\"akey\"]=mapValue{\t\texpiration: ds.Clock.Now().Add(500*time.Millisecond),\t\tvalue: \"avalue\", } ds.checkAndDeleteExpiredKeys() if _, exists := ds.Data[\"akey\"] ; !exists { t.Errorf(\"Key-value not found but should\") } ds.Clock = FutureClock ds.checkAndDeleteExpiredKeys() if _, exists := ds.Data[\"akey\"] ; exists { t.Errorf(\"Key-value found but shouldn't\") }}In the test above, we generated two different implementors of the Clock interface: one providing a past time and one providing a future time. This provides to our test the ability to change between those two in between the assertions leaving the test with no possibility to create a false positive or negative and also without adding any extra delay. We could also use more fine-grained results in Now() functions of the two implementations in order to give a more precise result (in our case 500ms are enough!) between those two implementations.Other ApproachesIt might be a little weird to Inject a Dependency in our library that will only be used while unit testing some of the provided functionalities. However, this is an essential process when we want to achieve such a decoupling.Another commonly process that is using when we have to test a function which requires a resource that we do not control in Monkey Patching (or mocking). Mocking is primarily used in unit testing. An object under test may have dependencies on other (complex) objects. To isolate the behavior of the object you want to replace the other objects by mocks that simulate the behavior of the real objects. This is useful if the real objects are impractical to incorporate into the unit test. In short, mocking is creating objects that simulate the behavior of real objects.In our case we could use one of the available mocking libraries. Some of theme are listed bellow: mock testify monkeyWrap upDecoupling a function from it’s external resources is essential for unit testing. Dependency Injection is the technique that we usually exploit to achieve this decoupling. In our case we showed how to test a function that uses current time and injected it to the function under test. Monkey patching is another commonly pattern used when it comes to test resources we do not own. So, choose your preferred one and keep testing!" }, { "title": "AquaGo - A Toy Project", "url": "/posts/AquaGo-A-Toy-Project/", "categories": "", "tags": "toy-project, golang, coding, oAuth, image-processing, LEGO", "date": "2020-09-01 03:40:00 +0800", "snippet": "Just imagine if you could have on your living’s room TV an aquarium! Wouldn’t that be nice, especially during the hot period of summertime? What about if you could add digital fishes and decorative stuff in this aquarium that you could create (physically or by design) with your own style?This is more or less what I got up with during this summer! A real toy project!Two beloved things helped me implement this project. The first one is the Go programming language (alongside ebiten a dead simple 2D gaming library for GO) and LEGOs which I used to decorate and give “life” to my digital aquarium.I hope you enjoy reading this as much I enjoyed working on this and you might want to give it a try!InspirationWhile watching a video of a tour in the LEGO house in Denmark I came across a really interesting (among a lot of) part! At 08:21 a visitor of the LEGO house can create with a few LEGO bricks a structure (sometimes they look like a fish!) that could be added “inside” a digital aquarium after a scanning process.That digital aquarium is consisted of a static background, some seaweeds made of LEGO bricks that wave, some background decorative stuff and the “fishes” that visitors make out of LEGOs after adding some facial stuff (mouth, eyes etc). The scanning process of each fish takes place in a special illuminated pad that visitors put their LEGO “fish” and a camera captures it.This is what gave inspiration to design and develop this project during the summer of 2020. I really enjoyed the process of designing, developing and using it as well!I propose you to watch the whole video as it is really interesting and maybe you could find something to play with. 😉Setting RequirementsLanguage 💻Before starting implementing this, the idea was wandering around my mind for a few days. It was clear that I would need some image processing and a gaming (2D) library. Go was already chosen as it is something I am learning at this period of time and would like to improve my skill at it somehow. Ebiten supported my choice, as Go is not a graphics/game oriented language and I had some concerns about using this at this project.Assets 🐠So for giving life to my digital aquarium I would require to have a few things inside it to make it look alive! First of all I would like some decorative objects that could be moved (draggable) inside the aquarium. These objects are usually some seaweeds, some rocks, or even a treasure chest! I would also like to have some bubbles which would wobble towards the surface and have no other purpose rather than making te aquarium looking more realistic (as it couldn’t)! The last and more complex parts are the “fishes”. Fishes would move “freely” inside the aquarium to different directions, with different speeds (or just stopped) and change moving angles! Of course, we would like to see them waving as they move around!Image Transformation 🏞In the image transformation part, it is clear that there are lots of different libraries out there and of course there is always the OpenCV project which could be there for me if needed. So image processing was not something to wonder about. The images should need some sort of transformation. Resizing and cropping would be the simpler tasks. But among them, it would be pretty cool if the application could remove any static background and make it transparent giving a more realistic result to our assets.No Interaction 🙌The last requirement was to be able to use it with less interaction as possible. I didn’t want to rerun or rebuild my app when I wanted to add a new element (decorative or fish) in the aquarium. For this reason, I wanted an online hosting where I could put my images (capture by a smart phone!) and the application could download them afterword and put those stuff inside the aquarium. Isn’t that nice? That’s all. Nothing more - nothing less (at least in the beginning)!Development🎲🎲 It seems reasonable that, as real-life seems to move a little bit randomly, a random number generator function should be extensively used at initialization and runtime in order to create a more realistic and fuzzy result.🎲🎲 So prepare to get surprisedAll necessary parameters that could be changed to meet someone’s needs are saved as env vars or within a special file ‘.env’. More details for this can be found in the project’s README.Tools / LibrariesApart from Go language and the Ebiten library that used for the visualization ad movement of the aquarium’s assets, the bild library used as a collection of parallel image processing algorithms.For the online storage and retrieval mechanism for the assets, Google Drive used and exploited through the Google API v3 . To make those tasks easier a Google Drive’s API wrapper library developed and used. The library supports the auth/authz part as well as general methods to search for files (using some filter criteria) and to download specific files. Exactly what we needed for our case!BootstrappingSo what happens when the application starts. First of all, it tries to retrieve all the newly added assets from the remote Google’s Drive folders. This is done through a goroutine which is initiated to check every minute for newly added images and download if found from the Google Drive. The mechanism to do this scheduling was implemented this way:ticker := time.NewTicker(1 * time.Minute)go func() { for range ticker.C { downloadNewImages(gogledrive, os.Getenv(\"BGFOLDERID\"), gdriveBgFolder, bgFolder) downloadNewImages(gogledrive, os.Getenv(\"FGFOLDERID\"), gdriveFgFolder, fgFolder) }}()Using this way we will see our assets to pop up into the aquarium gradually.For each new image, a background separation and removal algorithm removes the background based on the fact that is is a single solid color. For this reason, all images are captured with a solid color background(generally white but it could be any other color)!This is the image transformation that occurs to each retrieved asset:Then, all transformed images/assets are placed within the aquarium with some specific and some random initial values as described in the following sections.BubblesFrom the first frame and (about) every 1” one new bubble pops in from the bottom of the aquarium and starts to move to the top. Each bubble differs in size and speed and moves upwards and also to a little bit to the left or to the right randomly. In fact, it moves to one direction and based on a threshold it can randomly change direction.randDirection := Direction(rand.Intn(2))if randDirection == 0 { randDirection = -1}scale := Scale(rand.Float64() + 0.5)b := &amp;Bubble{ image: bblImage, //we could use different images in the future but now we use a single one x: 100, //leave a standard margin from the left y: screenHeight, //bottom of the image direction: randDirection, //random dinitial irection - left/right speed: Speed(rand.Intn(int(maxSpeed+1)) + 1), //random speed scale: scale, //random scale}Using this loop all bubbles were updated with a frequency based on their speed! Bubbles could disappear randomly or after reaching the top of the screen and direction could randomly change!for idx, b := range g.bubbles { //Determines speed by changing bubble's position according to frame count if frameCount%int(b.speed*-1+(maxSpeed+2)) == 0 { _, h := b.image.Size() //remove if bbl reaches top or randomly if b.y &lt;= -h || rand.Float64() &lt; bblDisappearPossibility { g.bubbles = append(g.bubbles[:idx], g.bubbles[idx+1:]...) bblMux.Unlock() continue } b.y-- // 33% chance to go just straight up // looks more smooth in transition if rand.Intn(3) == 1 { if rand.Float64() &lt; bblDirectionPossibility { b.direction *= -1 } b.x += int(b.direction) } }}All this resulted in this beautiful result:Background ItemsBackground items are retrieved through Google Drive at bootstrap and are checked for newly added every minute. If any new asset is found it is processed and then randomly is being placed into the aquarium. These items are able to be repositioned by dragging them so we could decorate the aquarium based on our mood! These items are a bit dull as their only option is the image used and their position.Foreground ItemsTime to give some life to our aquarium! This one was the biggest challenge! Digital fishes should move around the aquarium to different directions with different speeds and angles and all of them could be randomly change - something as real fish in an aquarium! So, as you can see, the fish structure holds all those relevant data alongside some basic information for the current position and its name (that was the file’s name)!w, h := fishImage.Size()randDirection := Direction(rand.Intn(2))if randDirection == 0 { randDirection = -1}angleDirection := rand.Intn(2)if angleDirection == 0 { angleDirection = -1}f := &amp;Fish{ image: fishImage, name: d.Name(), x: rand.Intn(screenWidth - w), y: rand.Intn(screenHeight - h), direction: randDirection, speed: Speed(rand.Intn(int(maxSpeed+1)) + 1), angle: rand.Float64() / 2 * float64(angleDirection), skew: float64(0.05), skewDirection: 1,}The angle is used to allow fishes to move upwards and downwards while skew and skew direction used to transform each fish in order to see them ‘swimming’ - somehow. Skew changes direction more frequently when fishes move faster compared to the slower one.This is the part that updates our fishes in the aquarium:for _, f := range g.fishes { //Determines speed by changing fishe's position according to frame count if frameCount%int(f.speed*-1+(maxSpeed+2)) == 0 { w, h := f.image.Size() if f.y &lt;= 0 || f.y &gt;= screenHeight-h { f.angle *= -1 } else { if rand.Float64() &lt; fishAnglePossibility { angleDirection := rand.Intn(2) if angleDirection == 0 { angleDirection = -1 } f.angle += (rand.Float64() - 0.5) / 2 } } changeSpeedRand := rand.Float64() if changeSpeedRand &lt; 0.05 &amp;&amp; f.speed &gt; 1 { f.speed-- } if changeSpeedRand &gt; 0.95 &amp;&amp; f.speed &lt;= maxSpeed { f.speed++ } if f.speed &gt; 0 { //change direction if close to left/right or randomly if f.x &lt;= 0 || f.x &gt;= screenWidth-w || rand.Float64() &lt; fishDirectionPossibility { f.direction = Direction(int(f.direction) * -1) } f.x += int(f.direction) f.y += int(f.angle * 3) if frameCount%(int(f.speed*-1+(maxSpeed+2))) == 0 { if f.skew &gt;= 0.2 || f.skew &lt;= -0.2 { f.skewDirection *= -1 } f.skew += float64(f.skewDirection) * 0.01 } } }}ResultTime for fun 🎆Combining all those we have something that meets our requirements:Project’s ChallengesThe most challenging aspect of this project was the part of designing. One basic requirement should be met - be as easy as possible to update the aquarium’s content. This was the reason that google drive set up, background removal algorithm incorporated, polling for new images added, and so on…The next challenging part was to make this app run effortlessly by any user. So easy as grabbing the code, setting up Google Drive’s oAuth and run it!The last one had to do with the gaming part of the app. Now being a game developer made me try harder to get up with how are game engines (such as ebiten) usually work. To be honest, I really enjoyed this part as this introduced me to a new field!Improvements The first major improvement that has to be done has to do with the background removal algorithm (contour extraction could be used here). There are numerous algorithms to use, however, we have to keep performance in mind which is critical at least at startup time. Some tasks could be executed concurrently. For instance, each image could be downloaded and then processed asynchronously. Also we might consider removing the necessity to use Google Drive in case someone doesn’t want to use it. Fish waving function could also be improved to provide a more realistic result. More InfoThe whole project is hosted under https://github.com/mzampetakis/aquago repo where you can find more technical details of the project. The Google’s drive wrapper library is located under https://github.com/mzampetakis/gogle-drive repo with some technical details as well.Contributions are more than welcome in form of PRs, issues, even with a simple comment down here! But most importantly I would like to know if you enjoyed this!" }, { "title": "Log Requests in Go", "url": "/posts/Log-Requests-in-Go/", "categories": "", "tags": "golang, coding", "date": "2020-08-18 04:40:00 +0800", "snippet": "It’s a common sense that logging your HTTP request in your application is essential. The reasons for doing so are numerous. Error reporting, tracing, monitoring, performance tuning and so on.One of the easiest way to do this in Go is by using an HTTP middleware. Bellow we will show a simple but elegant way of doing it!What is a middlewareWhen we build a web server it is common to use some logic among multiple endpoints to perform some tasks. Some of these tasks might be to authenticate the user, to add some headers in the response or just log something! An HTTP middleware in Go allows to abstract and share functionality among multiple requests.So, an HTTP middleware allows us to organize this functionality in a higher level. More specifically, between the router and the handlers.A Simple middlewareA minimum middleware set up in Go requires setting up the handler and a handle function with the desired middleware.package mainimport (\t\"log\"\t\"net/http\")func myMiddleware(next http.Handler) http.Handler {\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\t\tlog.Println(\"Entering middleware\")\t\tnext.ServeHTTP(w, r)\t\tlog.Println(\"Leaving middlewareOne\")\t})}func handleFunc(w http.ResponseWriter, r *http.Request) {\tlog.Println(\"Executing handleFunc\")\tw.Write([]byte(\"OK\"))}func main() {\tmux := http.NewServeMux()\thandler := http.HandlerFunc(handleFunc)\tmux.Handle(\"/\", myMiddleware(handler))\tlog.Println(\"Listening on :8000...\")\tlog.Fatal(http.ListenAndServe(\":8000\", mux))}The magic happens in line 24 where we enforce the myMiddleware to be used by our handler for our handler. Running the above will give us the following result:2020/08/12 20:08:35 Listening on 8000...2020/08/12 20:08:40 Entering middleware2020/08/12 20:08:40 Executing handleFunc2020/08/12 20:08:40 Leaving middlewareThis makes sense how can we exploit middlewares to achieve the desired result every single time. Middlewares can be cascaded but this requires to take extra care for the order that will be used.Log RequestsBack to the request logging we require some request details to be logged in our application. Thankfully all this information is within *http.Request. So for our example we could log the request using this middleware:func myMiddleware(next http.Handler) http.Handler {\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\t\tlog.Println(\"Entering middleware\")\t\tlog.Printf(\"%s : Method: %s | URL: %s%s | Proto: %s\",\t\t\ttime.Now().Format(time.RFC3339), r.Method, r.Host, r.URL, r.Proto)\t\tnext.ServeHTTP(w, r)\t\tlog.Println(\"Leaving middleware\")\t})}At line 4 the middleware logs a Datetime alongside some basic information of the request. The output we get is as follows:2020/08/12 20:44:15 Listening on 8000...2020/08/12 20:44:20 Entering middleware2020/08/12 20:44:20 2020-08-17T22:14:40+03:00 : Method: GET | URL: localhost:8000/ | Proto: HTTP/1.12020/08/12 20:44:20 Executing handleFunc2020/08/12 20:44:20 Leaving middleware There is no need to log explicitly date and time as log already prefixes our logging string.Tracing supportMoving a step forward for our request logger we would like to add some tracing information for each request. Apart from creating and logging a unique request id we should also save this generated uuid within each request. There is no better place to save this other that the HTTP context. Context package makes it easy to pass request-scoped values, cancelation signals, and deadlines across API boundaries to all the goroutines involved in handling a request.More about the Go’s context package can be found here.The following middleware generates a uuid, logs at the request logging and passes it inside the request’s context.func myMiddleware(next http.Handler) http.Handler {\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\t\tlog.Println(\"Entering myMiddleware\")\t\trequestID := uuid.New()\t\tlog.Printf(\"%s : %s: Method: %s | URL: %s%s | Proto: %s\",\t\t\ttime.Now().Format(time.RFC3339), requestID, r.Method, r.Host, r.URL, r.Proto)\t\tctx := context.WithValue(r.Context(), \"request-id\", requestID)\t\tnext.ServeHTTP(w, r.WithContext(ctx))\t\tlog.Println(\"Leaving myMiddleware\")\t})}Now, the request log prints the generated request uuid and has the following format:2020/08/12 22:17:36 Listening on 8000...2020/08/12 22:17:39 Entering middleware2020/08/12 22:17:39 2020-08-17T22:17:39+03:00 : a81ea2c1-55c3-4a31-b331-b5acf2cfac6d: Method: GET | URL: localhost:8000/ | Proto: HTTP/1.12020/08/12 22:17:39 Executing handleFunc2020/08/12 22:17:39 Leaving middlewareFrom this point we have access to this request-id within our handler function allowing us to log with this unique id. Keep in mind that now our middleware has a double role. The first is to log each request and the second on is to populate the context with a request-id. This might not be a preferred solution, however, it was easier to demonstrate it here like this.At this point all seem good. That’s not completely correct. As seen heat this issue: Using a context.Context Value key of type string is a terrible idea and walks into the minefield of a global namespace. We should’ve outlawed it from day 1.All context value keys should be made from user-defined types.Which means we have to use an alternative/custom type for our request-id context key.The following could solve the issue we just describef by introducing the RequestIDKey type and use it when setting the value into context.// RequestIDKey type is the type used as key to store request-id into contexttype RequestIDKey stringfunc myMiddleware(next http.Handler) http.Handler {\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\t\tlog.Println(\"Entering myMiddleware\")\t\trequestID := uuid.New()\t\tlog.Printf(\"%s : %s: Method: %s | URL: %s%s | Proto: %s\",\t\t\ttime.Now().Format(time.RFC3339), requestID, r.Method, r.Host, r.URL, r.Proto)\t\trequestIDKey := RequestIDKey(\"request-id\")\t\tctx := context.WithValue(r.Context(), requestIDKey, requestID)\t\tnext.ServeHTTP(w, r.WithContext(ctx))\t\tlog.Println(\"Leaving myMiddleware\")\t})}From now on, the same type RequestIDKey should be used in order to retrieve the request-id whenever needed!Log responseWe can now easily log the response of each handler. Just by extending our middleware after the log.Println(\"Leaving middleware\") line and using the http.ResponseWriter object. We could use the same middleware or another one depending on our case.ConclusionAs mentioned earlier, middlewares have many use cases. Logging is just one of them. Middlwares are used in most API services in Go for authentication and authorization, for compression, for recovery for setting content type and many more cases.Extra caution should be taken when using multiple middlewares as well as when group of routes are used!" }, { "title": "Hello Blog", "url": "/posts/Hello-Blog/", "categories": "", "tags": "blogging", "date": "2020-07-15 04:20:00 +0800", "snippet": "Hey everyone 👋🏻! I am Michalis Zampetakis.This is my first attempt to write my own thoughts and various things I am learning or trying from time to time! I hope you will enjoy this and, why not, reach me out to discuss some of these topics that interest me!TopicsPosts in this blog will mostly concern topics such as: OSS Go(lang) Testing LEGOs ❤Happy reading !and stay tuned… You can choose the theme (dark or light) you prefer at the bottom left corner of the site to meet your preference!" } ]
